{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dvc-tfrec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "pOVSwH4biYjA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  !wget http://files.fast.ai/data/dogscats.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DnhVi6SViblF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !unzip dogscats.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rTLK3H-gicgQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import threading, random, sys, os\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import six"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m_eWsw8Kl3aR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fsFut-wcr7WE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_THREADS = 2 #@param {type:\"integer\"}\n",
        "OUTPUT_DIR = './' #@param {type:\"string\"}\n",
        "TRAIN_DIR = './dogscats/train' #@param {type:\"string\"}\n",
        "VALID_DIR = './dogscats/valid' #@param {type:\"string\"}\n",
        "NUM_TRAIN_SHARDS = 2 #@param {type:\"integer\"}\n",
        "NUM_VALID_SHARDS = 2 #@param {type:\"integer\"}\n",
        "JPEG_FILE_EXT = '.jpg' #@param {type:\"string\"}\n",
        "BUCKET = 'gs://gs_colab' #@param {type:\"string\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KKsp8-up13Ri",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iujbyKM2z9Q4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _int64_feature(value):\n",
        "  if not isinstance(value, list):\n",
        "    value = [value]\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  if six.PY3 and isinstance(value, str):\n",
        "    value = six.binary_type(value, encoding='utf-8')\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vc2KRKWcj9uH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _process_image_files_batch(thread_index, ranges, name, filenames, labels, num_shards):\n",
        "  num_threads = len(ranges)\n",
        "  assert not num_shards % num_threads\n",
        "  num_shards_per_batch = num_shards // num_threads\n",
        "\n",
        "  shard_ranges = np.linspace(ranges[thread_index][0], ranges[thread_index][1], num_shards_per_batch + 1).astype(int)\n",
        "  num_files_in_thread = ranges[thread_index][1] - ranges[thread_index][0]\n",
        "\n",
        "  counter = 0\n",
        "  for s in range(num_shards_per_batch):\n",
        "    # Generate a sharded version of the file name, e.g. 'train-00002-of-00010'\n",
        "    shard = thread_index * num_shards_per_batch + s\n",
        "    output_filename = '%s-%.5d-of-%.5d' % (name, shard, num_shards)\n",
        "    output_file = os.path.join(OUTPUT_DIR, output_filename)\n",
        "    writer = tf.io.TFRecordWriter(output_file)\n",
        "\n",
        "    shard_counter = 0\n",
        "    files_in_shard = np.arange(shard_ranges[s], shard_ranges[s + 1], dtype=int)\n",
        "\n",
        "    for i in files_in_shard:\n",
        "      filename = filenames[i]\n",
        "      label = labels[i]\n",
        "\n",
        "      with tf.gfile.GFile(filename, 'rb') as f:\n",
        "        image_buffer = f.read()\n",
        "        example = tf.train.Example(features=tf.train.Features(feature={\n",
        "          'image': _bytes_feature(image_buffer),\n",
        "          'label': _int64_feature(label),\n",
        "        }))\n",
        "        writer.write(example.SerializeToString())\n",
        "        \n",
        "      shard_counter += 1\n",
        "      counter += 1\n",
        "\n",
        "      if not counter % 1000:\n",
        "        print(f'{datetime.now()} [thread {thread_index}]: Processed {counter} of {num_files_in_thread} images in thread batch.')\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    writer.close()\n",
        "    print(f'{datetime.now()} [thread {thread_index}]: Wrote {shard_counter} images to {output_file}')\n",
        "    sys.stdout.flush()\n",
        "    shard_counter = 0\n",
        "  print(f'{datetime.now()} [thread {thread_index}]: Wrote {counter} images to {num_files_in_thread} shards.')\n",
        "  sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vl7OSMpfnusM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _process_image_files(name, filenames, labels, num_shards):\n",
        "  spacing = np.linspace(0, len(filenames), NUM_THREADS + 1).astype(np.int)\n",
        "  ranges = []\n",
        "  threads = []\n",
        "  for i in range(len(spacing) - 1):\n",
        "    ranges.append([spacing[i], spacing[i + 1]])\n",
        "\n",
        "  print(f'Launching {NUM_THREADS} threads for spacings: {ranges}')\n",
        "  sys.stdout.flush()\n",
        "\n",
        "  coord = tf.train.Coordinator()\n",
        "\n",
        "  threads = []\n",
        "  for thread_index in range(len(ranges)):\n",
        "    args = (thread_index, ranges, name, filenames, labels, num_shards)\n",
        "    t = threading.Thread(target=_process_image_files_batch, args=args)\n",
        "    t.start()\n",
        "    threads.append(t)\n",
        "\n",
        "  coord.join(threads)\n",
        "  \n",
        "  print(f'{datetime.now()}: Finished writing all {len(filenames)} images in data set.')\n",
        "  sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GROzPFxptkEU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _find_image_files(data_dir):\n",
        "  synsets = ['cats', 'dogs']\n",
        "\n",
        "  labels = []\n",
        "  filenames = []\n",
        "\n",
        "  for i, synset in enumerate(synsets):\n",
        "    jpeg_file_path = f'{data_dir}/{synset}/*{JPEG_FILE_EXT}'\n",
        "    matching_files = tf.gfile.Glob(jpeg_file_path)\n",
        "    labels.extend([i] * len(matching_files))\n",
        "    filenames.extend(matching_files)\n",
        "\n",
        "  print(f'Found {len(filenames)} JPEG files across {len(synsets)} labels inside {data_dir}.')\n",
        "  return filenames, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RtcHU__asiQZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _process_dataset(name, directory, num_shards):\n",
        "  filenames, labels = _find_image_files(directory)\n",
        "  _process_image_files(name, filenames, labels, num_shards)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I3_7seR-viZU",
        "colab_type": "code",
        "outputId": "ace25ecd-8875-4214-d93a-fcda57a33c3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "_process_dataset('valid', VALID_DIR, NUM_VALID_SHARDS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 JPEG files across 2 labels inside ./dogscats/valid.\n",
            "Launching 2 threads for spacings: [[0, 1000], [1000, 2000]]\n",
            "2019-03-22 08:42:23.758890 [thread 0]: Processed 1000 of 1000 images in thread batch.\n",
            "2019-03-22 08:42:23.760710 [thread 0]: Wrote 1000 images to ./valid-00000-of-00002\n",
            "2019-03-22 08:42:23.763128 [thread 1]: Processed 1000 of 1000 images in thread batch.\n",
            "2019-03-22 08:42:23.764385 [thread 1]: Wrote 1000 images to ./valid-00001-of-00002\n",
            "2019-03-22 08:42:23.765273 [thread 1]: Wrote 1000 images to 1000 shards.\n",
            "2019-03-22 08:42:23.769293 [thread 0]: Wrote 1000 images to 1000 shards.\n",
            "2019-03-22 08:42:24.282481: Finished writing all 2000 images in data set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0OtNq_Fxw-nT",
        "colab_type": "code",
        "outputId": "992c6df3-8e75-4c03-905c-45510faba5c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "cell_type": "code",
      "source": [
        "_process_dataset('train', TRAIN_DIR, NUM_TRAIN_SHARDS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 23000 JPEG files across 2 labels inside ./dogscats/train.\n",
            "Launching 2 threads for spacings: [[0, 11500], [11500, 23000]]\n",
            "2019-03-22 08:42:32.902963 [thread 1]: Processed 1000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:32.912562 [thread 0]: Processed 1000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:33.455519 [thread 1]: Processed 2000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:33.460451 [thread 0]: Processed 2000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:34.124575 [thread 0]: Processed 3000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:34.157232 [thread 1]: Processed 3000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:34.743346 [thread 0]: Processed 4000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:34.774315 [thread 1]: Processed 4000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:35.258749 [thread 0]: Processed 5000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:35.295373 [thread 1]: Processed 5000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:35.816093 [thread 1]: Processed 6000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:35.875832 [thread 0]: Processed 6000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:36.349876 [thread 1]: Processed 7000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:36.417044 [thread 0]: Processed 7000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:36.871124 [thread 1]: Processed 8000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:36.925189 [thread 0]: Processed 8000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:37.387282 [thread 1]: Processed 9000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:37.429009 [thread 0]: Processed 9000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:38.037844 [thread 1]: Processed 10000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:38.045888 [thread 0]: Processed 10000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:38.546187 [thread 0]: Processed 11000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:38.570685 [thread 1]: Processed 11000 of 11500 images in thread batch.\n",
            "2019-03-22 08:42:38.807207 [thread 0]: Wrote 11500 images to ./train-00000-of-00002\n",
            "2019-03-22 08:42:38.808845 [thread 0]: Wrote 11500 images to 11500 shards.\n",
            "2019-03-22 08:42:38.823711 [thread 1]: Wrote 11500 images to ./train-00001-of-00002\n",
            "2019-03-22 08:42:38.824590 [thread 1]: Wrote 11500 images to 11500 shards.\n",
            "2019-03-22 08:42:39.290392: Finished writing all 23000 images in data set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SYXEV_hMyndv",
        "colab_type": "code",
        "outputId": "6ef37739-c49f-411d-b097-aefe3c287a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "ls -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1397072\n",
            "-rw-r--r-- 1 root root      2520 Mar 22 08:40 adc.json\n",
            "drwxrwxr-x 7 root root      4096 Oct  9  2016 \u001b[0m\u001b[01;34mdogscats\u001b[0m/\n",
            "-rw-r--r-- 1 root root 857214334 Apr  1  2017 dogscats.zip\n",
            "drwxr-xr-x 1 root root      4096 Mar  8 17:26 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root 241835086 Mar 22 08:42 train-00000-of-00002\n",
            "-rw-r--r-- 1 root root 285894746 Mar 22 08:42 train-00001-of-00002\n",
            "-rw-r--r-- 1 root root  20797080 Mar 22 08:42 valid-00000-of-00002\n",
            "-rw-r--r-- 1 root root  24829150 Mar 22 08:42 valid-00001-of-00002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lbb2UmFE0qFu",
        "colab_type": "code",
        "outputId": "9de4d7c8-ed51-4cba-dc43-c4ad088ded56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp train* $BUCKET/dvc_tfrec"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://train-00000-of-00002 [Content-Type=application/octet-stream]...\n",
            "/ [0 files][    0.0 B/230.6 MiB]                                                \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "Copying file://train-00001-of-00002 [Content-Type=application/octet-stream]...\n",
            "|\n",
            "Operation completed over 2 objects/503.3 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BKtTC-a22jDB",
        "colab_type": "code",
        "outputId": "1389b97c-cd5d-4e37-fca3-fb2c48076df6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp valid* $BUCKET/dvc_tfrec"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://valid-00000-of-00002 [Content-Type=application/octet-stream]...\n",
            "Copying file://valid-00001-of-00002 [Content-Type=application/octet-stream]...\n",
            "- [2 files][ 43.5 MiB/ 43.5 MiB]                                                \n",
            "Operation completed over 2 objects/43.5 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ULGn2SFD27el",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}