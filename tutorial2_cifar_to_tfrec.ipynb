{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar-to-tfrec.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "IH2St3XvTOSF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os, sys, tarfile\n",
        "\n",
        "from six.moves import cPickle as pickle\n",
        "from six.moves import urllib\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yUvkZMCpTVj8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BASE_URL = 'https://www.cs.toronto.edu/~kriz/'\n",
        "CIFAR_FILE_NAMES = ['cifar-10-python.tar.gz', 'cifar-100-python.tar.gz']\n",
        "CIFAR_DOWNLOAD_URLS = [BASE_URL + name for name in CIFAR_FILE_NAMES]\n",
        "CIFAR_LOCAL_FOLDERS = ['cifar-10', 'cifar-100']\n",
        "EXTRACT_FOLDERS = ['cifar-10-batches-py', 'cifar-100-python']\n",
        "\n",
        "DATA_DIR = './data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AnNRTOa2TZNZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def download_and_extract(data_dir, file_name, url):\n",
        "  \"\"\"Download CIFAR if not already downloaded.\"\"\"\n",
        "  filepath = os.path.join(data_dir, file_name)\n",
        "  if tf.gfile.Exists(filepath):\n",
        "    return filepath\n",
        "  if not tf.gfile.Exists(data_dir):\n",
        "    tf.gfile.MakeDirs(data_dir)\n",
        "\n",
        "  urllib.request.urlretrieve(url, filepath)\n",
        "  tarfile.open(os.path.join(filepath), 'r:gz').extractall(data_dir)\n",
        "  return filepath"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xkee4Ox4TD-F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _int64_feature(value):\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "\n",
        "def _get_file_names(folder):\n",
        "  \"\"\"Returns the file names expected to exist in the input_dir.\"\"\"\n",
        "  assert folder in ['cifar-10', 'cifar-100']\n",
        "\n",
        "  file_names = {}\n",
        "  if folder == 'cifar-10':\n",
        "    file_names['train'] = ['data_batch_%d' % i for i in range(1, 5)]\n",
        "    file_names['validation'] = ['data_batch_5']\n",
        "    file_names['train_all'] = ['data_batch_%d' % i for i in range(1, 6)]\n",
        "    file_names['test'] = ['test_batch']\n",
        "  else:\n",
        "    file_names['train_all'] = ['train']\n",
        "    file_names['test'] = ['test']\n",
        "    # Split in `convert_to_tfrecord` function\n",
        "    file_names['train'] = ['train']\n",
        "    file_names['validation'] = ['train']\n",
        "  return file_names\n",
        "\n",
        "\n",
        "def read_pickle_from_file(filename):\n",
        "  with tf.gfile.Open(filename, 'rb') as f:\n",
        "    if sys.version_info >= (3, 0):\n",
        "      data_dict = pickle.load(f, encoding='bytes')\n",
        "    else:\n",
        "      data_dict = pickle.load(f)\n",
        "  return data_dict\n",
        "\n",
        "\n",
        "def convert_to_tfrecord(input_files, output_file, folder):\n",
        "  \"\"\"Converts files with pickled data to TFRecords.\"\"\"\n",
        "  assert folder in ['cifar-10', 'cifar-100']\n",
        "\n",
        "  print('Generating %s' % output_file)\n",
        "  with tf.python_io.TFRecordWriter(output_file) as record_writer:\n",
        "    for input_file in input_files:\n",
        "      data_dict = read_pickle_from_file(input_file)\n",
        "      data = data_dict[b'data']\n",
        "      try:\n",
        "        labels = data_dict[b'labels']\n",
        "      except KeyError:\n",
        "        labels = data_dict[b'fine_labels']\n",
        "\n",
        "      if folder == 'cifar-100' and input_file.endswith('train.tfrecords'):\n",
        "        data = data[:40000]\n",
        "        labels = labels[:40000]\n",
        "      elif folder == 'cifar-100' and input_file.endswith(\n",
        "          'validation.tfrecords'):\n",
        "        data = data[40000:]\n",
        "        labels = labels[40000:]\n",
        "\n",
        "      num_entries_in_batch = len(labels)\n",
        "\n",
        "      for i in range(num_entries_in_batch):\n",
        "        example = tf.train.Example(\n",
        "            features=tf.train.Features(\n",
        "                feature={\n",
        "                    'image': _bytes_feature(data[i].tobytes()),\n",
        "                    'label': _int64_feature(labels[i])\n",
        "                }))\n",
        "        record_writer.write(example.SerializeToString())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hkdLLSDRTIAO",
        "colab_type": "code",
        "outputId": "b09dded9-fc59-4870-cd83-f67ba04d4e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "for file_name, url, folder, extract_folder in zip(\n",
        "    CIFAR_FILE_NAMES, CIFAR_DOWNLOAD_URLS, CIFAR_LOCAL_FOLDERS,\n",
        "    EXTRACT_FOLDERS):\n",
        "  print('Download from {} and extract.'.format(url))\n",
        "  data_dir = os.path.join(DATA_DIR, folder)\n",
        "  download_and_extract(data_dir, file_name, url)\n",
        "  file_names = _get_file_names(folder)\n",
        "  input_dir = os.path.join(data_dir, extract_folder)\n",
        "\n",
        "  for mode, files in file_names.items():\n",
        "    input_files = [os.path.join(input_dir, f) for f in files]\n",
        "    output_file = os.path.join(data_dir, mode + '.tfrecords')\n",
        "    try:\n",
        "      os.remove(output_file)\n",
        "    except OSError:\n",
        "      pass\n",
        "    convert_to_tfrecord(input_files, output_file, folder)\n",
        "\n",
        "print('Done!')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and extract.\n",
            "Generating ./data/cifar-10/train.tfrecords\n",
            "Generating ./data/cifar-10/validation.tfrecords\n",
            "Generating ./data/cifar-10/train_all.tfrecords\n",
            "Generating ./data/cifar-10/test.tfrecords\n",
            "Download from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz and extract.\n",
            "Generating ./data/cifar-100/train_all.tfrecords\n",
            "Generating ./data/cifar-100/test.tfrecords\n",
            "Generating ./data/cifar-100/train.tfrecords\n",
            "Generating ./data/cifar-100/validation.tfrecords\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}