{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dvc-tfrec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "pOVSwH4biYjA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  !wget http://files.fast.ai/data/dogscats.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DnhVi6SViblF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !unzip dogscats.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rTLK3H-gicgQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import threading, random, sys, os\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import six"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fsFut-wcr7WE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_THREADS = 2 #@param {type:\"integer\"}\n",
        "OUTPUT_DIR = './' #@param {type:\"string\"}\n",
        "TRAIN_DIR = './dogscats/train' #@param {type:\"string\"}\n",
        "VALID_DIR = './dogscats/valid' #@param {type:\"string\"}\n",
        "NUM_TRAIN_SHARDS = 2 #@param {type:\"integer\"}\n",
        "NUM_VALID_SHARDS = 2 #@param {type:\"integer\"}\n",
        "JPEG_FILE_EXT = '.jpg' #@param {type:\"string\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KKsp8-up13Ri",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iujbyKM2z9Q4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _int64_feature(value):\n",
        "  \"\"\"Wrapper for inserting int64 features into Example proto.\"\"\"\n",
        "  if not isinstance(value, list):\n",
        "    value = [value]\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9PpbN-wo0G8n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _bytes_feature(value):\n",
        "  \"\"\"Wrapper for inserting bytes features into Example proto.\"\"\"\n",
        "  if six.PY3 and isinstance(value, six.text_type):           \n",
        "    value = six.binary_type(value, encoding='utf-8') \n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vc2KRKWcj9uH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _process_image_files_batch(thread_index, ranges, name, filenames, labels, num_shards):\n",
        "  num_threads = len(ranges)\n",
        "  assert not num_shards % num_threads\n",
        "  num_shards_per_batch = num_shards // num_threads\n",
        "\n",
        "  shard_ranges = np.linspace(ranges[thread_index][0], ranges[thread_index][1], num_shards_per_batch + 1).astype(int)\n",
        "  num_files_in_thread = ranges[thread_index][1] - ranges[thread_index][0]\n",
        "\n",
        "  counter = 0\n",
        "  for s in range(num_shards_per_batch):\n",
        "    # Generate a sharded version of the file name, e.g. 'train-00002-of-00010'\n",
        "    shard = thread_index * num_shards_per_batch + s\n",
        "    output_filename = '%s-%.5d-of-%.5d' % (name, shard, num_shards)\n",
        "    output_file = os.path.join(OUTPUT_DIR, output_filename)\n",
        "    writer = tf.python_io.TFRecordWriter(output_file)\n",
        "\n",
        "    shard_counter = 0\n",
        "    files_in_shard = np.arange(shard_ranges[s], shard_ranges[s + 1], dtype=int)\n",
        "\n",
        "    for i in files_in_shard:\n",
        "      filename = filenames[i]\n",
        "      label = labels[i]\n",
        "\n",
        "      with tf.gfile.GFile(filename, 'rb') as f:\n",
        "        image_buffer = f.read()\n",
        "        example = tf.train.Example(features=tf.train.Features(feature={\n",
        "          'image/class/label': _int64_feature(label),\n",
        "          'image/filename': _bytes_feature(os.path.basename(filename)),\n",
        "          'image/encoded': _bytes_feature(image_buffer)}))\n",
        "        writer.write(example.SerializeToString())\n",
        "        \n",
        "      shard_counter += 1\n",
        "      counter += 1\n",
        "\n",
        "      if not counter % 1000:\n",
        "        print('%s [thread %d]: Processed %d of %d images in thread batch.' %\n",
        "              (datetime.now(), thread_index, counter, num_files_in_thread))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    writer.close()\n",
        "    print('%s [thread %d]: Wrote %d images to %s' %\n",
        "          (datetime.now(), thread_index, shard_counter, output_file))\n",
        "    sys.stdout.flush()\n",
        "    shard_counter = 0\n",
        "  print('%s [thread %d]: Wrote %d images to %d shards.' %\n",
        "        (datetime.now(), thread_index, counter, num_files_in_thread))\n",
        "  sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vl7OSMpfnusM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _process_image_files(name, filenames, labels, num_shards):\n",
        "  \"\"\"Process and save list of images as TFRecord of Example protos.\n",
        "  Args:\n",
        "    name: string, unique identifier specifying the data set\n",
        "    filenames: list of strings; each string is a path to an image file\n",
        "    labels: list of integer; each integer identifies the ground truth\n",
        "    num_shards: integer number of shards for this data set.\n",
        "  \"\"\"\n",
        "\n",
        "  spacing = np.linspace(0, len(filenames), NUM_THREADS + 1).astype(np.int)\n",
        "  ranges = []\n",
        "  threads = []\n",
        "  for i in range(len(spacing) - 1):\n",
        "    ranges.append([spacing[i], spacing[i + 1]])\n",
        "\n",
        "  print('Launching %d threads for spacings: %s' % (NUM_THREADS, ranges))\n",
        "  sys.stdout.flush()\n",
        "\n",
        "  coord = tf.train.Coordinator()\n",
        "\n",
        "  threads = []\n",
        "  for thread_index in range(len(ranges)):\n",
        "    args = (thread_index, ranges, name, filenames, labels, num_shards)\n",
        "    t = threading.Thread(target=_process_image_files_batch, args=args)\n",
        "    t.start()\n",
        "    threads.append(t)\n",
        "\n",
        "  coord.join(threads)\n",
        "  \n",
        "  print('%s: Finished writing all %d images in data set.' % (datetime.now(), len(filenames)))\n",
        "  sys.stdout.flush()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GROzPFxptkEU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _find_image_files(data_dir):\n",
        "  challenge_synsets = ['cats', 'dogs']\n",
        "\n",
        "  labels = []\n",
        "  filenames = []\n",
        "\n",
        "  label_index = 0\n",
        "\n",
        "  for synset in challenge_synsets:\n",
        "    jpeg_file_path = f'{data_dir}/{synset}/*{JPEG_FILE_EXT}'\n",
        "    matching_files = tf.gfile.Glob(jpeg_file_path)\n",
        "    labels.extend([label_index] * len(matching_files))\n",
        "    filenames.extend(matching_files)\n",
        "    label_index += 1\n",
        "\n",
        "  shuffled_index = list(range(len(filenames)))\n",
        "  random.seed(12345)\n",
        "  random.shuffle(shuffled_index)\n",
        "\n",
        "  filenames = [filenames[i] for i in shuffled_index]\n",
        "  labels = [labels[i] for i in shuffled_index]\n",
        "\n",
        "  print('Found %d JPEG files across %d labels inside %s.' % (len(filenames), len(challenge_synsets), data_dir))\n",
        "  return filenames, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RtcHU__asiQZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _process_dataset(name, directory, num_shards):\n",
        "  \"\"\"Process a complete data set and save it as a TFRecord.\n",
        "  Args:\n",
        "    name: string, unique identifier specifying the data set.\n",
        "    directory: string, root path to the data set.\n",
        "    num_shards: integer number of shards for this data set.\n",
        "  \"\"\"\n",
        "  filenames, labels = _find_image_files(directory)\n",
        "  _process_image_files(name, filenames, labels, num_shards)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I3_7seR-viZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "646f5050-c635-4496-a684-6bf7733b9933"
      },
      "cell_type": "code",
      "source": [
        "_process_dataset('valid', VALID_DIR, NUM_VALID_SHARDS)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 JPEG files across 2 labels inside ./dogscats/valid.\n",
            "Launching 2 threads for spacings: [[0, 1000], [1000, 2000]]\n",
            "2019-03-21 06:10:01.161528 [thread 1]: Processed 1000 of 1000 images in thread batch.\n",
            "2019-03-21 06:10:01.163761 [thread 1]: Wrote 1000 images to ./valid-00001-of-00002\n",
            "2019-03-21 06:10:01.165745 [thread 1]: Wrote 1000 images to 1000 shards.\n",
            "2019-03-21 06:10:01.177368 [thread 0]: Processed 1000 of 1000 images in thread batch.\n",
            "2019-03-21 06:10:01.181374 [thread 0]: Wrote 1000 images to ./valid-00000-of-00002\n",
            "2019-03-21 06:10:01.183504 [thread 0]: Wrote 1000 images to 1000 shards.\n",
            "2019-03-21 06:10:01.449832: Finished writing all 2000 images in data set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0OtNq_Fxw-nT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "e83b8c12-dff1-477a-c542-de7ec476de0f"
      },
      "cell_type": "code",
      "source": [
        "_process_dataset('train', TRAIN_DIR, NUM_TRAIN_SHARDS)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 23000 JPEG files across 2 labels inside ./dogscats/train.\n",
            "Launching 2 threads for spacings: [[0, 11500], [11500, 23000]]\n",
            "2019-03-21 05:56:14.393072 [thread 1]: Processed 1000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:14.420148 [thread 0]: Processed 1000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:15.204296 [thread 1]: Processed 2000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:15.232454 [thread 0]: Processed 2000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:15.920541 [thread 1]: Processed 3000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:16.063171 [thread 0]: Processed 3000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:16.580462 [thread 1]: Processed 4000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:16.746734 [thread 0]: Processed 4000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:17.237826 [thread 1]: Processed 5000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:17.400392 [thread 0]: Processed 5000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:17.930718 [thread 1]: Processed 6000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:18.212980 [thread 0]: Processed 6000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:18.596602 [thread 1]: Processed 7000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:18.876207 [thread 0]: Processed 7000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:19.247535 [thread 1]: Processed 8000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:19.526039 [thread 0]: Processed 8000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:19.880644 [thread 1]: Processed 9000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:20.199982 [thread 0]: Processed 9000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:20.700123 [thread 1]: Processed 10000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:20.862415 [thread 0]: Processed 10000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:21.370766 [thread 1]: Processed 11000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:21.517923 [thread 0]: Processed 11000 of 11500 images in thread batch.\n",
            "2019-03-21 05:56:21.698284 [thread 1]: Wrote 11500 images to ./train-00001-of-00002\n",
            "2019-03-21 05:56:21.702925 [thread 1]: Wrote 11500 images to 11500 shards.\n",
            "2019-03-21 05:56:21.782045 [thread 0]: Wrote 11500 images to ./train-00000-of-00002\n",
            "2019-03-21 05:56:21.783136 [thread 0]: Wrote 11500 images to 11500 shards.\n",
            "2019-03-21 05:56:22.533088: Finished writing all 23000 images in data set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SYXEV_hMyndv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "2be4120d-8841-45f6-c902-e28fcbe84601"
      },
      "cell_type": "code",
      "source": [
        "ls -l"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1398440\n",
            "drwxrwxr-x 7 root root      4096 Oct  9  2016 \u001b[0m\u001b[01;34mdogscats\u001b[0m/\n",
            "-rw-r--r-- 1 root root 857214334 Apr  1  2017 dogscats.zip\n",
            "drwxr-xr-x 1 root root      4096 Mar  8 17:26 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root 264165487 Mar 21 05:56 train-00000-of-00002\n",
            "-rw-r--r-- 1 root root 264854972 Mar 21 05:56 train-00001-of-00002\n",
            "-rw-r--r-- 1 root root  22848967 Mar 21 05:55 validation-00000-of-00002\n",
            "-rw-r--r-- 1 root root  22889488 Mar 21 05:55 validation-00001-of-00002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lbb2UmFE0qFu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a4196696-85aa-4480-d2c7-cb140f26ca95"
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp train* gs://gs_colab/dvc_tfrec"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://train-00000-of-00002 [Content-Type=application/octet-stream]...\n",
            "/ [0 files][    0.0 B/251.9 MiB]                                                \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "Copying file://train-00001-of-00002 [Content-Type=application/octet-stream]...\n",
            "/\n",
            "Operation completed over 2 objects/504.5 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BKtTC-a22jDB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "49a49127-24e1-4cd9-f2c6-350664b7521c"
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp valid* gs://gs_colab/dvc_tfrec"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://valid-00000-of-00002 [Content-Type=application/octet-stream]...\n",
            "Copying file://valid-00001-of-00002 [Content-Type=application/octet-stream]...\n",
            "\\\n",
            "Operation completed over 2 objects/43.6 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ULGn2SFD27el",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}