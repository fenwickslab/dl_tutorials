{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dvc_neck_shallow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Vu9FQ1kD34ju",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import functools, os, json, datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jdfNFS8q4H_B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BUCKET = 'gs://gs_colab' #@param {type: \"string\"}\n",
        "NUM_NECK = 1536\n",
        "\n",
        "BATCH_SIZE = 512 #@param {type: \"integer\"}\n",
        "EPOCHS = 50 #@param {type:\"integer\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UUoHe4JI4UBf",
        "colab_type": "code",
        "outputId": "38229816-8a25-4732-841e-dde4f54eb0eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "TPU_ADDRESS = f'grpc://{os.environ[\"COLAB_TPU_ADDR\"]}'\n",
        "TPU_ADDRESS"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'grpc://10.46.9.50:8470'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "LM5mrdER4Yl-",
        "colab_type": "code",
        "outputId": "c23fa1b3-3ed7-4992-da8a-3753ac2537f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "  \n",
        "# Upload the credentials to TPU.\n",
        "with tf.Session(TPU_ADDRESS) as sess:    \n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(sess, credentials=auth_info)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u0Msb1Ly4jFN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _parse(serialized_example):\n",
        "  features = tf.parse_single_example(\n",
        "    serialized_example,\n",
        "    features={\n",
        "        'neck': tf.FixedLenFeature([NUM_NECK], tf.float32),\n",
        "        \"label\": tf.FixedLenFeature([], tf.int64),\n",
        "    })\n",
        "\n",
        "  neck = features['neck']\n",
        "  label = features['label']\n",
        "  return neck, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H0trz-885EYK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_ds_from_tfrec(data_dir, training, batch_size=BATCH_SIZE, num_parallel_calls=2):\n",
        "  file_pattern = os.path.join(data_dir, 'train*' if training else 'valid*')\n",
        "  dataset = tf.data.Dataset.list_files(file_pattern)\n",
        "\n",
        "  def fetch_dataset(filename):\n",
        "    buffer_size = 8 * 1024 * 1024  # 8 MiB per file\n",
        "    dataset = tf.data.TFRecordDataset(filename, buffer_size=buffer_size)\n",
        "    return dataset\n",
        "\n",
        "  dataset = dataset.apply(\n",
        "    tf.data.experimental.parallel_interleave(\n",
        "      fetch_dataset, cycle_length=num_parallel_calls, sloppy=True))\n",
        "  \n",
        "  if training:\n",
        "    dataset = dataset.shuffle(50000, reshuffle_each_iteration=True)\n",
        "    \n",
        "  dataset = dataset.repeat()\n",
        "  \n",
        "  dataset = dataset.apply(\n",
        "    tf.data.experimental.map_and_batch(\n",
        "      _parse,\n",
        "      batch_size=batch_size,\n",
        "      num_parallel_batches=num_parallel_calls,\n",
        "      drop_remainder=True))\n",
        "\n",
        "  dataset = dataset.prefetch(tf.contrib.data.AUTOTUNE)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yQ8iWtxU6Ux6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = f'{BUCKET}/dvc_ir2'\n",
        "\n",
        "train_input_fn = lambda params: get_ds_from_tfrec(data_dir, training=True)\n",
        "valid_input_fn = lambda params: get_ds_from_tfrec(data_dir, training=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z43mnaVDhb5c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ShallowNet(tf.keras.Model):\n",
        "  def __init__(self, c=256):\n",
        "    super().__init__()\n",
        "    self.dense = tf.keras.layers.Dense(c, use_bias=False)\n",
        "    self.bn = tf.keras.layers.BatchNormalization()\n",
        "    self.linear = tf.keras.layers.Dense(2, use_bias=False)\n",
        "\n",
        "  def call(self, x):\n",
        "    return self.linear(tf.nn.relu(self.bn(self.dense(x))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eM35mI5u9Uhi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_fn(features, labels, mode, params):\n",
        "  phase = 1 if mode == tf.estimator.ModeKeys.TRAIN else 0\n",
        "  tf.keras.backend.set_learning_phase(phase)\n",
        "\n",
        "  model = ShallowNet()\n",
        "  logits = model(features)\n",
        "\n",
        "  loss = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n",
        "  step = tf.train.get_or_create_global_step()\n",
        "    \n",
        "  opt = tf.train.AdamOptimizer()\n",
        "  opt = tf.contrib.tpu.CrossShardOptimizer(opt)\n",
        "  with tf.control_dependencies(model.get_updates_for(features)):\n",
        "    train_op = opt.minimize(loss, global_step=step)\n",
        "\n",
        "  classes = tf.math.argmax(logits, axis=-1)\n",
        "  metric_fn = lambda classes, labels: {'accuracy': tf.metrics.accuracy(classes, labels)}\n",
        "  tpu_metrics = (metric_fn, [classes, labels])\n",
        "    \n",
        "  return tf.contrib.tpu.TPUEstimatorSpec(mode, loss=loss, train_op=train_op, \n",
        "                                           eval_metrics = tpu_metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UeyOIfPXl09Q",
        "colab_type": "code",
        "outputId": "77bc0ed3-4c3d-4827-fd27-c6725e9b86e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "len_train = 23000\n",
        "len_valid = 2000\n",
        "steps_per_epoch = len_train // BATCH_SIZE\n",
        "\n",
        "now = datetime.datetime.now()\n",
        "MODEL_DIR = BUCKET+\"/dvc_jobs/job-{}-{:02d}-{:02d}-{:02d}:{:02d}:{:02d}\".format(now.year, now.month, now.day, now.hour, now.minute, now.second)\n",
        "\n",
        "training_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS),\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "    iterations_per_loop=steps_per_epoch,\n",
        "    per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "   \n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    model_fn=model_fn,\n",
        "    model_dir=MODEL_DIR,\n",
        "    train_batch_size=BATCH_SIZE,\n",
        "    eval_batch_size=len_valid,\n",
        "    config=training_config)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7f666de8dd08>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.46.9.50:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6655ba6d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.46.9.50:8470', '_evaluation_master': 'grpc://10.46.9.50:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=44, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f6655ba6f60>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MbOPnOLYmt8Z",
        "colab_type": "code",
        "outputId": "ed2de61a-1149-4df0-d2a8-8ff4d35614cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3519
        }
      },
      "cell_type": "code",
      "source": [
        "estimator.train(train_input_fn, steps=steps_per_epoch*EPOCHS)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.46.9.50:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 8130153408989375718)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7695904695122032099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 13556633524374736780)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 13426122915025866855)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6674192379372603992)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8998334621038545895)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 13248422291116618100)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 16069063862413634381)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 11906012649496036807)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 12089439755400940157)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2629167936184775360)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42/model.ckpt.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 7 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.6092552, step = 44\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.48392382, step = 176 (9.745 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.5445\n",
            "INFO:tensorflow:examples/sec: 6934.81\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.44136307, step = 308 (10.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.9683\n",
            "INFO:tensorflow:examples/sec: 6639.77\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.41558212, step = 440 (10.604 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.4478\n",
            "INFO:tensorflow:examples/sec: 6373.28\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.42001104, step = 572 (9.599 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.7515\n",
            "INFO:tensorflow:examples/sec: 7040.75\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.32017004, step = 704 (9.671 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.6501\n",
            "INFO:tensorflow:examples/sec: 6988.86\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.34937242, step = 836 (9.328 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.1508\n",
            "INFO:tensorflow:examples/sec: 7245.2\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.31865218, step = 968 (9.710 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.5944\n",
            "INFO:tensorflow:examples/sec: 6960.31\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2998104, step = 1100 (10.317 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.7945\n",
            "INFO:tensorflow:examples/sec: 6550.79\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.31884924, step = 1232 (9.828 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.4298\n",
            "INFO:tensorflow:examples/sec: 6876.04\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.28721765, step = 1364 (9.993 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2045\n",
            "INFO:tensorflow:examples/sec: 6760.7\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.26316896, step = 1496 (9.593 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.7655\n",
            "INFO:tensorflow:examples/sec: 7047.95\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2914114, step = 1628 (10.343 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.7621\n",
            "INFO:tensorflow:examples/sec: 6534.18\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.32116503, step = 1760 (9.938 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2818\n",
            "INFO:tensorflow:examples/sec: 6800.29\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.25327578, step = 1892 (9.548 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.8247\n",
            "INFO:tensorflow:examples/sec: 7078.25\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.24706821, step = 2024 (9.425 sec)\n",
            "INFO:tensorflow:global_step/sec: 14.0058\n",
            "INFO:tensorflow:examples/sec: 7170.97\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2429006, step = 2156 (9.508 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.8834\n",
            "INFO:tensorflow:examples/sec: 7108.29\n",
            "INFO:tensorflow:Enqueue next (44) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (44) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 2200 into gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42/model.ckpt.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Loss for final step: 0.26209286.\n",
            "INFO:tensorflow:training_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.contrib.tpu.python.tpu.tpu_estimator.TPUEstimator at 0x7f6655ba6e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "GAb1SBHnns8v",
        "colab_type": "code",
        "outputId": "29bb518b-4c33-479c-84e5-0db3baf94636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "cell_type": "code",
      "source": [
        "estimator.evaluate(input_fn=valid_input_fn, steps=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py:2655: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-03-24T11:54:56Z\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42/model.ckpt-2200\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 7 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Evaluation [1/1]\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Finished evaluation at 2019-03-24-11:55:05\n",
            "INFO:tensorflow:Saving dict for global step 2200: accuracy = 0.76416016, global_step = 2200, loss = 1.089059\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2200: gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42/model.ckpt-2200\n",
            "INFO:tensorflow:evaluation_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.76416016, 'global_step': 2200, 'loss': 1.089059}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "TQSg8PsSvKtU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "4182dc8b-ac4f-4a6d-b88b-d423e2f8f698"
      },
      "cell_type": "code",
      "source": [
        "!gsutil rm -r $BUCKET/dvc_jobs"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removing gs://gs_colab/dvc_jobs/#1553345717566869...\n",
            "Removing gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42/#1553428490291525...\n",
            "Removing gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42/checkpoint#1553428493507214...\n",
            "Removing gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42/eval/#1553428506049038...\n",
            "/ [4 objects]                                                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m rm ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Removing gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42/eval/events.out.tfevents.1553428506.40d24201d47d#1553428507661950...\n",
            "Removing gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42/events.out.tfevents.1553428304.40d24201d47d#1553428495124716...\n",
            "Removing gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42/graph.pbtxt#1553428307461389...\n",
            "Removing gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42/model.ckpt-0.data-00000-of-00001#1553428312011949...\n",
            "Removing gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42/model.ckpt-0.index#1553428312580634...\n",
            "Removing gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42/model.ckpt-0.meta#1553428315787576...\n",
            "Removing gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42/model.ckpt-2200.data-00000-of-00001#1553428491110639...\n",
            "Removing gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42/model.ckpt-2200.index#1553428491927647...\n",
            "Removing gs://gs_colab/dvc_jobs/job-2019-03-24-11:51:42/model.ckpt-2200.meta#1553428494624836...\n",
            "/ [13 objects]                                                                  \n",
            "Operation completed over 13 objects.                                             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CpUVUY9Ujuvq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}